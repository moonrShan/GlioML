{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa55bed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.002621Z",
     "start_time": "2023-09-19T11:23:33.612609Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b72ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.018627Z",
     "start_time": "2023-09-19T11:23:35.003622Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=False, **kwargs):\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, final = False, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        start = time.time()\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...{i / len(self.labels) * 100}%\")\n",
    "            print(f\"{(time.time() - start) / 60} minutes\")\n",
    "            if (final):\n",
    "                predictor.fit(train_data=train_data[train_data[label] > float('-inf')]\n",
    "                              , tuning_data = tuning_data\n",
    "                              ,presets = 'best_quality'\n",
    "                              ,num_bag_folds = 5,num_bag_sets = 2\n",
    "                              , **kwargs)\n",
    "            else:\n",
    "                predictor.fit(train_data=train_data[train_data[label] > float('-inf')]\n",
    "                              , tuning_data = tuning_data\n",
    "                              ,presets = 'medium_quality'\n",
    "                              #,presets = 'best_quality'\n",
    "                              #,num_bag_folds = 5,num_bag_sets = 2\n",
    "                              , **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            \n",
    "            eval_dict[label] = predictor.evaluate(data[data[label] > float('-inf')], **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for i,label in enumerate(self.labels):\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...{i / len(self.labels) * 100}%\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ae94b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.066622Z",
     "start_time": "2023-09-19T11:23:35.020623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "187\n",
      "197\n",
      "1616\n",
      "665\n",
      "280\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "#1 Load my ccl's ssGSEA signature\n",
    "myCCLSignature = []\n",
    "for name in ['sample.c2.cp.biocarta.gct',\n",
    "             'sample.c2.cp.kegg.gct',\n",
    "             'sample.c2.cp.pid.gct',\n",
    "             'sample.c2.cp.reactome.gct',\n",
    "             'sample.c2.cp.wiki.gct',\n",
    "             'sample.c6.gct',\n",
    "             'sample.hallmark.gct']:    \n",
    "    with open(name, mode ='r')as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        CCLSignature = list(csvFile)[2:]\n",
    "        print(len(CCLSignature))\n",
    "    for i, row in enumerate(CCLSignature):\n",
    "        temp = CCLSignature[i][0].split('\\t')\n",
    "        if i > 0:\n",
    "            CCLSignature[i] = [temp[0]] + [float(d) for d in temp[2:]]\n",
    "        else:\n",
    "            CCLSignature[i] = [temp[0]] + temp[2:]\n",
    "    if not myCCLSignature:\n",
    "        myCCLSignature += CCLSignature\n",
    "    else:\n",
    "        myCCLSignature += CCLSignature[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ebef18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.824631Z",
     "start_time": "2023-09-19T11:23:35.068624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "187\n",
      "197\n",
      "1616\n",
      "665\n",
      "280\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "#2 Load CCLE ssGSEA signature\n",
    "CCLECCLSignature = []\n",
    "for name in ['ccle.c2.cp.biocarta.gct',\n",
    "             'ccle.c2.cp.kegg.gct',\n",
    "             'ccle.c2.cp.pid.gct',\n",
    "             'ccle.c2.cp.reactome.gct',\n",
    "             'ccle.c2.cp.wiki.gct',\n",
    "             'ccle.c6.gct',\n",
    "             'ccle.hallmark.gct']:\n",
    "    with open(name, mode ='r')as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        CCLSignature = list(csvFile)[2:]\n",
    "        print(len(CCLSignature))\n",
    "    for i, row in enumerate(CCLSignature):\n",
    "        temp = CCLSignature[i][0].split('\\t')\n",
    "        CCLSignature[i] = [temp[0]] + temp[2:]\n",
    "    if not CCLECCLSignature:\n",
    "        CCLECCLSignature += CCLSignature\n",
    "    else:\n",
    "        CCLECCLSignature += CCLSignature[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b85673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.840632Z",
     "start_time": "2023-09-19T11:23:35.825633Z"
    }
   },
   "outputs": [],
   "source": [
    "############new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6136f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.872630Z",
     "start_time": "2023-09-19T11:23:35.843636Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.1 load model\n",
    "modelMetaData = pd.read_csv('Model.csv', header=0)\n",
    "modelMetaData = modelMetaData[['ModelID','Age','Sex']]\n",
    "sex_mapping = {'Male': 1, 'Female': 0}\n",
    "modelMetaData['Sex'] = modelMetaData['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fb2549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.920633Z",
     "start_time": "2023-09-19T11:23:35.874636Z"
    }
   },
   "outputs": [],
   "source": [
    "metaDataDict = {}\n",
    "for index, row in modelMetaData.iterrows():\n",
    "    key = row['ModelID'] \n",
    "    value = [row['Age'], row['Sex']] \n",
    "    if key not in metaDataDict:\n",
    "        metaDataDict[key] = value\n",
    "    else:\n",
    "        raise Exception(\"duplicated Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b62ef3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:40.740325Z",
     "start_time": "2023-09-19T11:23:35.922631Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/nb52fxtx6g934cctxtd11mz40000gn/T/ipykernel_7352/2322606452.py:2: DtypeWarning: Columns (49,50,51,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mutationData = pd.read_csv('OmicsSomaticMutations.csv')\n"
     ]
    }
   ],
   "source": [
    "#2.2 load Mutation\n",
    "mutationData = pd.read_csv('OmicsSomaticMutations.csv')\n",
    "mutationData = mutationData[['ModelID','HugoSymbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80e741d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:40.756304Z",
     "start_time": "2023-09-19T11:23:40.741283Z"
    }
   },
   "outputs": [],
   "source": [
    "candidateKeyList = [\n",
    "    'MGMT', 'IDH1', 'IDH2', 'EGFR',\n",
    "    'TTN', 'MAPRE3', 'TP53', 'PIK3C2B', 'CIC', 'LRP2', 'LRP1', 'NRXN2', 'TEAD2', 'MYH3', 'NOTCH1', 'TFE3', 'PIK3R1', 'FRMD4A', 'PRCC', 'CHD3', 'BAG6', 'GLYR1', 'ADAM23', 'MSH6', 'ATRX',\n",
    "    'MUC16', 'PTEN', 'NF1', 'OBSN', 'FLG', 'RYR2', 'MUC17',\n",
    "    'BRAF', 'CDKN2A', 'CDKN2B', 'TERT', 'MYC'\n",
    "]\n",
    "candidateGeneMutationCount = {key: 0 for key in candidateKeyList}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a560b348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.003864Z",
     "start_time": "2023-09-19T11:23:40.759307Z"
    }
   },
   "outputs": [],
   "source": [
    "mutationDataDict = {}\n",
    "for index, row in mutationData.iterrows():\n",
    "    key = row['ModelID']\n",
    "    if key not in mutationDataDict:\n",
    "        mutationDataDict[key] = candidateGeneMutationCount.copy()\n",
    "    gene = row['HugoSymbol']\n",
    "    if gene in candidateGeneMutationCount:\n",
    "        mutationDataDict[key][row['HugoSymbol']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7b0a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.019876Z",
     "start_time": "2023-09-19T11:24:00.004821Z"
    }
   },
   "outputs": [],
   "source": [
    "#############new end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce386d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.115879Z",
     "start_time": "2023-09-19T11:24:00.021832Z"
    }
   },
   "outputs": [],
   "source": [
    "#3 Load CTRP cclName to AUC map\n",
    "cclToAUCdict = collections.defaultdict(list)\n",
    "with open('CTRP_CCL_AUC.gct', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    CTRPCCLAUC = list(csvFile)\n",
    "    CTRPCCLAUC = [''.join(sub).split('\\t') for sub in CTRPCCLAUC]\n",
    "    cclNames = CTRPCCLAUC[3][4:]\n",
    "\n",
    "for i,cclName in enumerate(cclNames):\n",
    "    cclToAUCdict[cclName] = [float( '-inf' if sub[4+i] == 'NaN' else sub[4+i]) for sub in CTRPCCLAUC[7:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc80f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.163833Z",
     "start_time": "2023-09-19T11:24:00.116833Z"
    }
   },
   "outputs": [],
   "source": [
    "#4 Load ccleID to ctrpName map\n",
    "CCLEidToCTRPNameDict = collections.defaultdict(str)\n",
    "CCLEidToDiseaseName = collections.defaultdict(str)\n",
    "with open('sample_info.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    mapInfos = list(csvFile)\n",
    "    for mapInfo in mapInfos[1:]:\n",
    "        CCLEidToCTRPNameDict[mapInfo[0]] = mapInfo[2]  \n",
    "        CCLEidToDiseaseName[mapInfo[0]] = mapInfo[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8996ddbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.179832Z",
     "start_time": "2023-09-19T11:24:00.164832Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc53a03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.228441Z",
     "start_time": "2023-09-19T11:24:00.180832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIOCARTA_GRANULOCYTES_PATHWAY</th>\n",
       "      <th>BIOCARTA_LYM_PATHWAY</th>\n",
       "      <th>BIOCARTA_BLYMPHOCYTE_PATHWAY</th>\n",
       "      <th>BIOCARTA_CARM_ER_PATHWAY</th>\n",
       "      <th>BIOCARTA_LAIR_PATHWAY</th>\n",
       "      <th>BIOCARTA_VDR_PATHWAY</th>\n",
       "      <th>BIOCARTA_MTA3_PATHWAY</th>\n",
       "      <th>BIOCARTA_GABA_PATHWAY</th>\n",
       "      <th>BIOCARTA_EGFR_SMRTE_PATHWAY</th>\n",
       "      <th>BIOCARTA_MONOCYTE_PATHWAY</th>\n",
       "      <th>...</th>\n",
       "      <th>HALLMARK_COAGULATION</th>\n",
       "      <th>HALLMARK_IL2_STAT5_SIGNALING</th>\n",
       "      <th>HALLMARK_BILE_ACID_METABOLISM</th>\n",
       "      <th>HALLMARK_PEROXISOME</th>\n",
       "      <th>HALLMARK_ALLOGRAFT_REJECTION</th>\n",
       "      <th>HALLMARK_SPERMATOGENESIS</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING_UP</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING_DN</th>\n",
       "      <th>HALLMARK_PANCREAS_BETA_CELLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>THP1_d3_B.TPM</th>\n",
       "      <td>0.991211</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.876465</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.595703</td>\n",
       "      <td>0.475098</td>\n",
       "      <td>0.492432</td>\n",
       "      <td>0.594238</td>\n",
       "      <td>0.986328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.810059</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.337402</td>\n",
       "      <td>0.670410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2D_1.TPM</th>\n",
       "      <td>0.160278</td>\n",
       "      <td>0.161499</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.379395</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.363525</td>\n",
       "      <td>0.187866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.221802</td>\n",
       "      <td>0.194458</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.555664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.343262</td>\n",
       "      <td>0.248169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRId7CWa.quant.TPM</th>\n",
       "      <td>0.438232</td>\n",
       "      <td>0.443604</td>\n",
       "      <td>0.540527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.303955</td>\n",
       "      <td>0.583496</td>\n",
       "      <td>0.429932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927246</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.484619</td>\n",
       "      <td>0.130737</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.053558</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H7.TPM</th>\n",
       "      <td>0.553711</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.427979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724609</td>\n",
       "      <td>0.403809</td>\n",
       "      <td>0.853027</td>\n",
       "      <td>0.493896</td>\n",
       "      <td>0.511230</td>\n",
       "      <td>0.531738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>0.248291</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.189209</td>\n",
       "      <td>0.544434</td>\n",
       "      <td>0.707520</td>\n",
       "      <td>0.644043</td>\n",
       "      <td>0.258057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THP1_d3_A.TPM</th>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>0.795898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548340</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>0.474854</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.826660</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.877930</td>\n",
       "      <td>0.928223</td>\n",
       "      <td>0.791504</td>\n",
       "      <td>0.947754</td>\n",
       "      <td>0.933105</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.819824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                   BIOCARTA_GRANULOCYTES_PATHWAY  BIOCARTA_LYM_PATHWAY  \\\n",
       "Name                                                                      \n",
       "THP1_d3_B.TPM                            0.991211              0.985352   \n",
       "2D_1.TPM                                 0.160278              0.161499   \n",
       "TRId7CWa.quant.TPM                       0.438232              0.443604   \n",
       "H7.TPM                                   0.553711              0.562500   \n",
       "THP1_d3_A.TPM                            0.992676              0.992676   \n",
       "\n",
       "0                   BIOCARTA_BLYMPHOCYTE_PATHWAY  BIOCARTA_CARM_ER_PATHWAY  \\\n",
       "Name                                                                         \n",
       "THP1_d3_B.TPM                           0.984375                  0.876465   \n",
       "2D_1.TPM                                0.059387                  0.379395   \n",
       "TRId7CWa.quant.TPM                      0.540527                  0.000000   \n",
       "H7.TPM                                  0.427979                  1.000000   \n",
       "THP1_d3_A.TPM                           0.973633                  0.795898   \n",
       "\n",
       "0                   BIOCARTA_LAIR_PATHWAY  BIOCARTA_VDR_PATHWAY  \\\n",
       "Name                                                              \n",
       "THP1_d3_B.TPM                    0.993652              0.595703   \n",
       "2D_1.TPM                         0.045349              1.000000   \n",
       "TRId7CWa.quant.TPM               0.506836              0.303955   \n",
       "H7.TPM                           0.724609              0.403809   \n",
       "THP1_d3_A.TPM                    1.000000              0.548340   \n",
       "\n",
       "0                   BIOCARTA_MTA3_PATHWAY  BIOCARTA_GABA_PATHWAY  \\\n",
       "Name                                                               \n",
       "THP1_d3_B.TPM                    0.475098               0.492432   \n",
       "2D_1.TPM                         0.089844               0.554199   \n",
       "TRId7CWa.quant.TPM               0.583496               0.429932   \n",
       "H7.TPM                           0.853027               0.493896   \n",
       "THP1_d3_A.TPM                    0.615723               0.447266   \n",
       "\n",
       "0                   BIOCARTA_EGFR_SMRTE_PATHWAY  BIOCARTA_MONOCYTE_PATHWAY  \\\n",
       "Name                                                                         \n",
       "THP1_d3_B.TPM                          0.594238                   0.986328   \n",
       "2D_1.TPM                               0.363525                   0.187866   \n",
       "TRId7CWa.quant.TPM                     1.000000                   0.700195   \n",
       "H7.TPM                                 0.511230                   0.531738   \n",
       "THP1_d3_A.TPM                          0.474854                   0.989258   \n",
       "\n",
       "0                   ...  HALLMARK_COAGULATION  HALLMARK_IL2_STAT5_SIGNALING  \\\n",
       "Name                ...                                                       \n",
       "THP1_d3_B.TPM       ...              0.675781                      0.810059   \n",
       "2D_1.TPM            ...              0.025284                      0.065186   \n",
       "TRId7CWa.quant.TPM  ...              0.927246                      0.736328   \n",
       "H7.TPM              ...              0.822754                      0.816406   \n",
       "THP1_d3_A.TPM       ...              0.691406                      0.826660   \n",
       "\n",
       "0                   HALLMARK_BILE_ACID_METABOLISM  HALLMARK_PEROXISOME  \\\n",
       "Name                                                                     \n",
       "THP1_d3_B.TPM                            0.680176             0.774902   \n",
       "2D_1.TPM                                 0.221802             0.194458   \n",
       "TRId7CWa.quant.TPM                       0.484619             0.130737   \n",
       "H7.TPM                                   0.113708             0.248291   \n",
       "THP1_d3_A.TPM                            0.710938             0.877930   \n",
       "\n",
       "0                   HALLMARK_ALLOGRAFT_REJECTION  HALLMARK_SPERMATOGENESIS  \\\n",
       "Name                                                                         \n",
       "THP1_d3_B.TPM                           0.928711                  0.793457   \n",
       "2D_1.TPM                                0.019119                  0.555664   \n",
       "TRId7CWa.quant.TPM                      0.436523                  0.053558   \n",
       "H7.TPM                                  0.477051                  0.189209   \n",
       "THP1_d3_A.TPM                           0.928223                  0.791504   \n",
       "\n",
       "0                   HALLMARK_KRAS_SIGNALING  HALLMARK_KRAS_SIGNALING_UP  \\\n",
       "Name                                                                      \n",
       "THP1_d3_B.TPM                      1.000000                    0.880859   \n",
       "2D_1.TPM                           0.000000                    0.037323   \n",
       "TRId7CWa.quant.TPM                 0.354004                    0.771484   \n",
       "H7.TPM                             0.544434                    0.707520   \n",
       "THP1_d3_A.TPM                      0.947754                    0.933105   \n",
       "\n",
       "0                   HALLMARK_KRAS_SIGNALING_DN  HALLMARK_PANCREAS_BETA_CELLS  \n",
       "Name                                                                          \n",
       "THP1_d3_B.TPM                         0.337402                      0.670410  \n",
       "2D_1.TPM                              0.343262                      0.248169  \n",
       "TRId7CWa.quant.TPM                    0.968750                      0.720703  \n",
       "H7.TPM                                0.644043                      0.258057  \n",
       "THP1_d3_A.TPM                         0.476562                      0.819824  \n",
       "\n",
       "[5 rows x 3284 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction data \n",
    "predictData = pd.DataFrame(data = myCCLSignature).transpose()\n",
    "new_header = predictData.iloc[0] \n",
    "predictData = predictData[1:] \n",
    "predictData.columns = new_header \n",
    "predictData = predictData.apply(pd.to_numeric, errors='ignore')\n",
    "predictData = predictData.set_index(['Name'])\n",
    "predictData = normalize(predictData)\n",
    "predictData = predictData.astype('float16')\n",
    "predictData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a614de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.420442Z",
     "start_time": "2023-09-19T11:24:01.230441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26 entries, THP1_d3_B.TPM to HCd7CWa.quant.TPM\n",
      "Columns: 3284 entries, BIOCARTA_GRANULOCYTES_PATHWAY to HALLMARK_PANCREAS_BETA_CELLS\n",
      "dtypes: float16(3284)\n",
      "memory usage: 168.5 KB\n"
     ]
    }
   ],
   "source": [
    "predictData.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6935a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.626443Z",
     "start_time": "2023-09-19T11:24:01.421443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare train set\n",
    "trainData = pd.DataFrame(data = CCLECCLSignature).transpose()\n",
    "new_header = trainData.iloc[0] \n",
    "trainData = trainData[1:] \n",
    "trainData.columns = new_header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52014506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.327450Z",
     "start_time": "2023-09-19T11:24:01.627444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIOCARTA_GRANULOCYTES_PATHWAY</th>\n",
       "      <th>BIOCARTA_LYM_PATHWAY</th>\n",
       "      <th>BIOCARTA_BLYMPHOCYTE_PATHWAY</th>\n",
       "      <th>BIOCARTA_CARM_ER_PATHWAY</th>\n",
       "      <th>BIOCARTA_LAIR_PATHWAY</th>\n",
       "      <th>BIOCARTA_VDR_PATHWAY</th>\n",
       "      <th>BIOCARTA_MTA3_PATHWAY</th>\n",
       "      <th>BIOCARTA_GABA_PATHWAY</th>\n",
       "      <th>BIOCARTA_EGFR_SMRTE_PATHWAY</th>\n",
       "      <th>BIOCARTA_MONOCYTE_PATHWAY</th>\n",
       "      <th>...</th>\n",
       "      <th>HALLMARK_COAGULATION</th>\n",
       "      <th>HALLMARK_IL2_STAT5_SIGNALING</th>\n",
       "      <th>HALLMARK_BILE_ACID_METABOLISM</th>\n",
       "      <th>HALLMARK_PEROXISOME</th>\n",
       "      <th>HALLMARK_ALLOGRAFT_REJECTION</th>\n",
       "      <th>HALLMARK_SPERMATOGENESIS</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING_UP</th>\n",
       "      <th>HALLMARK_KRAS_SIGNALING_DN</th>\n",
       "      <th>HALLMARK_PANCREAS_BETA_CELLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-001113</th>\n",
       "      <td>-4026.645913</td>\n",
       "      <td>-2439.765461</td>\n",
       "      <td>-4667.433695</td>\n",
       "      <td>4245.632425</td>\n",
       "      <td>-2634.558718</td>\n",
       "      <td>6679.038788</td>\n",
       "      <td>5122.943551</td>\n",
       "      <td>233.525589</td>\n",
       "      <td>3240.420783</td>\n",
       "      <td>-1373.036419</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.480372</td>\n",
       "      <td>2013.491371</td>\n",
       "      <td>90.175905</td>\n",
       "      <td>4123.227172</td>\n",
       "      <td>-741.313831</td>\n",
       "      <td>-557.117109</td>\n",
       "      <td>2439.206531</td>\n",
       "      <td>-861.816581</td>\n",
       "      <td>-3301.023113</td>\n",
       "      <td>-1722.977475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000242</th>\n",
       "      <td>-3937.716661</td>\n",
       "      <td>-2621.452770</td>\n",
       "      <td>-4241.404568</td>\n",
       "      <td>4712.036616</td>\n",
       "      <td>-3189.755692</td>\n",
       "      <td>7318.928946</td>\n",
       "      <td>5045.464864</td>\n",
       "      <td>-1759.629780</td>\n",
       "      <td>3165.594813</td>\n",
       "      <td>-1523.257437</td>\n",
       "      <td>...</td>\n",
       "      <td>503.868738</td>\n",
       "      <td>2278.095889</td>\n",
       "      <td>1099.536405</td>\n",
       "      <td>4735.463738</td>\n",
       "      <td>245.521668</td>\n",
       "      <td>-1527.711407</td>\n",
       "      <td>3270.470271</td>\n",
       "      <td>-351.167918</td>\n",
       "      <td>-3621.638189</td>\n",
       "      <td>-2433.575233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000327</th>\n",
       "      <td>-3781.416152</td>\n",
       "      <td>-2313.928569</td>\n",
       "      <td>-4325.047772</td>\n",
       "      <td>5313.421286</td>\n",
       "      <td>-2977.444387</td>\n",
       "      <td>5864.860635</td>\n",
       "      <td>4989.815628</td>\n",
       "      <td>754.096070</td>\n",
       "      <td>2148.453587</td>\n",
       "      <td>-1585.842870</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.972973</td>\n",
       "      <td>2174.382638</td>\n",
       "      <td>1877.876002</td>\n",
       "      <td>5461.676880</td>\n",
       "      <td>-374.525043</td>\n",
       "      <td>-1131.652527</td>\n",
       "      <td>2941.386241</td>\n",
       "      <td>-475.140822</td>\n",
       "      <td>-3416.527063</td>\n",
       "      <td>-998.619342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000461</th>\n",
       "      <td>-3736.974891</td>\n",
       "      <td>-1104.574918</td>\n",
       "      <td>-4948.954189</td>\n",
       "      <td>4512.332186</td>\n",
       "      <td>-2696.549331</td>\n",
       "      <td>6554.031705</td>\n",
       "      <td>4377.850873</td>\n",
       "      <td>-550.037643</td>\n",
       "      <td>3431.112552</td>\n",
       "      <td>-1386.421102</td>\n",
       "      <td>...</td>\n",
       "      <td>694.296581</td>\n",
       "      <td>2594.017464</td>\n",
       "      <td>-367.008470</td>\n",
       "      <td>4193.268771</td>\n",
       "      <td>312.949334</td>\n",
       "      <td>-1275.923638</td>\n",
       "      <td>3834.275855</td>\n",
       "      <td>-95.907985</td>\n",
       "      <td>-3930.183840</td>\n",
       "      <td>-1971.890027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000792</th>\n",
       "      <td>-2075.019365</td>\n",
       "      <td>1703.994143</td>\n",
       "      <td>-1812.061451</td>\n",
       "      <td>4141.948015</td>\n",
       "      <td>448.719648</td>\n",
       "      <td>6202.852062</td>\n",
       "      <td>4702.842570</td>\n",
       "      <td>-1424.053292</td>\n",
       "      <td>2439.967871</td>\n",
       "      <td>2108.238933</td>\n",
       "      <td>...</td>\n",
       "      <td>1771.136924</td>\n",
       "      <td>3038.181715</td>\n",
       "      <td>-129.839290</td>\n",
       "      <td>4039.550791</td>\n",
       "      <td>949.878642</td>\n",
       "      <td>-1170.344231</td>\n",
       "      <td>3728.075095</td>\n",
       "      <td>-368.635379</td>\n",
       "      <td>-4096.710474</td>\n",
       "      <td>-1964.779113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           BIOCARTA_GRANULOCYTES_PATHWAY  BIOCARTA_LYM_PATHWAY  \\\n",
       "Name                                                              \n",
       "ACH-001113                   -4026.645913          -2439.765461   \n",
       "ACH-000242                   -3937.716661          -2621.452770   \n",
       "ACH-000327                   -3781.416152          -2313.928569   \n",
       "ACH-000461                   -3736.974891          -1104.574918   \n",
       "ACH-000792                   -2075.019365           1703.994143   \n",
       "\n",
       "0           BIOCARTA_BLYMPHOCYTE_PATHWAY  BIOCARTA_CARM_ER_PATHWAY  \\\n",
       "Name                                                                 \n",
       "ACH-001113                  -4667.433695               4245.632425   \n",
       "ACH-000242                  -4241.404568               4712.036616   \n",
       "ACH-000327                  -4325.047772               5313.421286   \n",
       "ACH-000461                  -4948.954189               4512.332186   \n",
       "ACH-000792                  -1812.061451               4141.948015   \n",
       "\n",
       "0           BIOCARTA_LAIR_PATHWAY  BIOCARTA_VDR_PATHWAY  \\\n",
       "Name                                                      \n",
       "ACH-001113           -2634.558718           6679.038788   \n",
       "ACH-000242           -3189.755692           7318.928946   \n",
       "ACH-000327           -2977.444387           5864.860635   \n",
       "ACH-000461           -2696.549331           6554.031705   \n",
       "ACH-000792             448.719648           6202.852062   \n",
       "\n",
       "0           BIOCARTA_MTA3_PATHWAY  BIOCARTA_GABA_PATHWAY  \\\n",
       "Name                                                       \n",
       "ACH-001113            5122.943551             233.525589   \n",
       "ACH-000242            5045.464864           -1759.629780   \n",
       "ACH-000327            4989.815628             754.096070   \n",
       "ACH-000461            4377.850873            -550.037643   \n",
       "ACH-000792            4702.842570           -1424.053292   \n",
       "\n",
       "0           BIOCARTA_EGFR_SMRTE_PATHWAY  BIOCARTA_MONOCYTE_PATHWAY  ...  \\\n",
       "Name                                                                ...   \n",
       "ACH-001113                  3240.420783               -1373.036419  ...   \n",
       "ACH-000242                  3165.594813               -1523.257437  ...   \n",
       "ACH-000327                  2148.453587               -1585.842870  ...   \n",
       "ACH-000461                  3431.112552               -1386.421102  ...   \n",
       "ACH-000792                  2439.967871                2108.238933  ...   \n",
       "\n",
       "0           HALLMARK_COAGULATION  HALLMARK_IL2_STAT5_SIGNALING  \\\n",
       "Name                                                             \n",
       "ACH-001113            -63.480372                   2013.491371   \n",
       "ACH-000242            503.868738                   2278.095889   \n",
       "ACH-000327             -9.972973                   2174.382638   \n",
       "ACH-000461            694.296581                   2594.017464   \n",
       "ACH-000792           1771.136924                   3038.181715   \n",
       "\n",
       "0           HALLMARK_BILE_ACID_METABOLISM  HALLMARK_PEROXISOME  \\\n",
       "Name                                                             \n",
       "ACH-001113                      90.175905          4123.227172   \n",
       "ACH-000242                    1099.536405          4735.463738   \n",
       "ACH-000327                    1877.876002          5461.676880   \n",
       "ACH-000461                    -367.008470          4193.268771   \n",
       "ACH-000792                    -129.839290          4039.550791   \n",
       "\n",
       "0           HALLMARK_ALLOGRAFT_REJECTION  HALLMARK_SPERMATOGENESIS  \\\n",
       "Name                                                                 \n",
       "ACH-001113                   -741.313831               -557.117109   \n",
       "ACH-000242                    245.521668              -1527.711407   \n",
       "ACH-000327                   -374.525043              -1131.652527   \n",
       "ACH-000461                    312.949334              -1275.923638   \n",
       "ACH-000792                    949.878642              -1170.344231   \n",
       "\n",
       "0           HALLMARK_KRAS_SIGNALING  HALLMARK_KRAS_SIGNALING_UP  \\\n",
       "Name                                                              \n",
       "ACH-001113              2439.206531                 -861.816581   \n",
       "ACH-000242              3270.470271                 -351.167918   \n",
       "ACH-000327              2941.386241                 -475.140822   \n",
       "ACH-000461              3834.275855                  -95.907985   \n",
       "ACH-000792              3728.075095                 -368.635379   \n",
       "\n",
       "0           HALLMARK_KRAS_SIGNALING_DN  HALLMARK_PANCREAS_BETA_CELLS  \n",
       "Name                                                                  \n",
       "ACH-001113                -3301.023113                  -1722.977475  \n",
       "ACH-000242                -3621.638189                  -2433.575233  \n",
       "ACH-000327                -3416.527063                   -998.619342  \n",
       "ACH-000461                -3930.183840                  -1971.890027  \n",
       "ACH-000792                -4096.710474                  -1964.779113  \n",
       "\n",
       "[5 rows x 3284 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter valid ID\n",
    "validSet = set()\n",
    "for name in trainData['Name']:\n",
    "    if CCLEidToCTRPNameDict[name] in cclToAUCdict:\n",
    "        validSet.add(name)\n",
    "trainData = trainData.loc[trainData['Name'].isin(validSet)]\n",
    "trainData = trainData.reset_index(drop = True)\n",
    "trainData = trainData.set_index(['Name'])\n",
    "trainData = trainData.apply(pd.to_numeric)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ce4112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.390964Z",
     "start_time": "2023-09-19T11:24:02.375965Z"
    }
   },
   "outputs": [],
   "source": [
    "if not all(trainData.columns == predictData.columns):\n",
    "    raise Exception(\"Column do not match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4c8b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.406965Z",
     "start_time": "2023-09-19T11:24:02.391964Z"
    }
   },
   "outputs": [],
   "source": [
    "###new\n",
    "trainData['Age'] = trainData.index.map(lambda x: metaDataDict[x][0])\n",
    "trainData['Sex'] = trainData.index.map(lambda x: metaDataDict[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ed8251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.437967Z",
     "start_time": "2023-09-19T11:24:02.408964Z"
    }
   },
   "outputs": [],
   "source": [
    "#counts not matter\n",
    "for geneName in candidateKeyList:\n",
    "    trainData[geneName] = trainData.index.map(lambda x: 1 if x in mutationDataDict and mutationDataDict[x][geneName] > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5770b06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:04.902903Z",
     "start_time": "2023-09-19T11:24:02.440964Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData = normalize(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794fb296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.124906Z",
     "start_time": "2023-09-19T11:24:04.904905Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData = trainData.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "258d3930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.139907Z",
     "start_time": "2023-09-19T11:24:05.125906Z"
    }
   },
   "outputs": [],
   "source": [
    "### new end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f9ca95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.586929Z",
     "start_time": "2023-09-19T11:24:05.140908Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#labels data\n",
    "labelsDataOriginal = pd.DataFrame(columns = [sub[1] for sub in CTRPCCLAUC[7:]])\n",
    "for name in trainData.index:\n",
    "    labelsDataOriginal.loc[len(labelsDataOriginal.index)] = cclToAUCdict[CCLEidToCTRPNameDict[name]]\n",
    "labelsDataOriginal = labelsDataOriginal.set_index(trainData.index)\n",
    "labelsDataOriginal = labelsDataOriginal.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "651b49a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.634930Z",
     "start_time": "2023-09-19T11:24:05.604930Z"
    }
   },
   "outputs": [],
   "source": [
    "#add high priority at the begining. e.g dasatinib\n",
    "labels = list(labelsDataOriginal.columns)\n",
    "labels = ['dasatinib'] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "062064dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.650931Z",
     "start_time": "2023-09-19T11:24:05.635931Z"
    }
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "problem_types = ['regression'] \n",
    "eval_metrics = ['mean_squared_error']\n",
    "time_limit = 60 * 60 * 24\n",
    "tops = [100,300,600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6fece86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 636 entries, ACH-001113 to ACH-000052\n",
      "Columns: 3323 entries, BIOCARTA_GRANULOCYTES_PATHWAY to MYC\n",
      "dtypes: float16(3323)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "trainData.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be7a1878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 636 entries, ACH-001113 to ACH-000052\n",
      "Columns: 481 entries, zebularine to GSK-J4\n",
      "dtypes: float16(481)\n",
      "memory usage: 639.1 KB\n"
     ]
    }
   ],
   "source": [
    "labelsDataOriginal.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a029b871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:40:04.997510Z",
     "start_time": "2023-09-19T11:28:16.854634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 86400s\n",
      "AutoGluon will save models to \"dasatinib/GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Model_dasatinib/Predictor_dasatinib/\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.4.0: Mon Mar  6 21:00:41 PST 2023; root:xnu-8796.101.5~3/RELEASE_ARM64_T8103\n",
      "Disk Space Avail:   320.46 GB / 494.38 GB (64.8%)\n",
      "Train Data Rows:    619\n",
      "Train Data Columns: 3323\n",
      "Label Column: dasatinib\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working ondasatinib\n",
      "Fitting TabularPredictor for label: dasatinib ...0.0%\n",
      "2.2681554158528647e-05 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tAvailable Memory:                    432.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.11 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 36 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['OBSN']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['WP_INSULIN_SIGNALING_IN_ADIPOCYTES_DIABETIC_CONDITION', 'WP_CELLS_AND_MOLECULES_INVOLVED_IN_LOCAL_ACUTE_INFLAMMATORY_RESPONSE', 'WP_PATHOGENIC_ESCHERICHIA_COLI_INFECTION', 'WP_ARRHYTHMOGENIC_RIGHT_VENTRICULAR_CARDIOMYOPATHY', 'WP_ENDOCHONDRAL_OSSIFICATION']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 5 | ['WP_INSULIN_SIGNALING_IN_ADIPOCYTES_DIABETIC_CONDITION', 'WP_CELLS_AND_MOLECULES_INVOLVED_IN_LOCAL_ACUTE_INFLAMMATORY_RESPONSE', 'WP_PATHOGENIC_ESCHERICHIA_COLI_INFECTION', 'WP_ARRHYTHMOGENIC_RIGHT_VENTRICULAR_CARDIOMYOPATHY', 'WP_ENDOCHONDRAL_OSSIFICATION']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 3317 | ['BIOCARTA_GRANULOCYTES_PATHWAY', 'BIOCARTA_LYM_PATHWAY', 'BIOCARTA_BLYMPHOCYTE_PATHWAY', 'BIOCARTA_CARM_ER_PATHWAY', 'BIOCARTA_LAIR_PATHWAY', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 3281 | ['BIOCARTA_GRANULOCYTES_PATHWAY', 'BIOCARTA_LYM_PATHWAY', 'BIOCARTA_BLYMPHOCYTE_PATHWAY', 'BIOCARTA_CARM_ER_PATHWAY', 'BIOCARTA_LAIR_PATHWAY', ...]\n",
      "\t\t('int', ['bool']) :   36 | ['MGMT', 'IDH1', 'IDH2', 'EGFR', 'TTN', ...]\n",
      "\t24.4s = Fit runtime\n",
      "\t3317 features in original data used to generate 3317 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.08 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 24.8s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 495, Val Rows: 124\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 86375.2s of the 86375.15s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.024 GB out of 0.359 GB available memory (32.919%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.38 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ... Training model for up to 86370.8s of the 86370.74s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.024 GB out of 0.356 GB available memory (33.197%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.38 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: LightGBMXT ... Training model for up to 86370.29s of the 86370.24s of remaining time.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y4/nb52fxtx6g934cctxtd11mz40000gn/T/ipykernel_7352/743919240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmulti_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultilabelPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmulti_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#multi_predictor = MultilabelPredictor.load(save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#result = multi_predictor.predict(predictData)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/y4/nb52fxtx6g934cctxtd11mz40000gn/T/ipykernel_7352/3564636717.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, final, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m                               , **kwargs)\n\u001b[1;32m     94\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 predictor.fit(train_data=train_data[train_data[label] > float('-inf')]\n\u001b[0m\u001b[1;32m     96\u001b[0m                               \u001b[0;34m,\u001b[0m \u001b[0mtuning_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuning_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                               \u001b[0;34m,\u001b[0m\u001b[0mpresets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'medium_quality'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_weighted_ensemble'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\n\u001b[0m\u001b[1;32m    952\u001b[0m                           \u001b[0mholdout_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                           \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learner is already fit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         self._train_multi_and_ensemble(X=X,\n\u001b[0m\u001b[1;32m    107\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                        \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2091\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\n\u001b[0m\u001b[1;32m   2094\u001b[0m                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,\n\u001b[0m\u001b[1;32m    438\u001b[0m                                                 level=level, infer_limit=infer_limit, infer_limit_batch_size=infer_limit_batch_size, base_model_names=base_model_names, **core_kwargs)\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         return self._train_multi(X=X_init, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled,\n\u001b[0m\u001b[1;32m    549\u001b[0m                                  models=models, level=level, stack_name=stack_name, compute_score=compute_score, fit_kwargs=fit_kwargs, **kwargs)\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m             model_names_trained = self._train_multi_initial(X=X, y=y, models=models, k_fold=k_fold, n_repeats=n_repeats_initial, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                                             feature_prune_kwargs=feature_prune_kwargs, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2065\u001b[0m             \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_repeats_initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m             models = self._train_multi_fold(models=models, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   1956\u001b[0m                                             time_limit=time_limit, time_split=time_split, time_ratio=time_ratio, **fit_args)\n\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2032\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m             \u001b[0mmodel_name_trained_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   1850\u001b[0m                 \u001b[0mbagged_model_fit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bagged_model_fit_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeat_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeat_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m             model_names_trained = self._train_and_save(\n\u001b[0m\u001b[1;32m   1853\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1542\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \"\"\"\n\u001b[0;32m-> 1485\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_fit_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36m_validate_fit_memory_usage\u001b[0;34m(self, mem_error_threshold, mem_warning_threshold, mem_size_threshold, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# Skip memory check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mapprox_mem_size_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmem_size_threshold\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mapprox_mem_size_req\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem_size_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_memory_usage_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# Model is smaller than the min threshold to check available mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mestimate_memory_usage\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \"\"\"\n\u001b[1;32m   1502\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Only estimate memory usage after the model is initialized.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py\u001b[0m in \u001b[0;36m_estimate_memory_usage\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# self.num_classes could be None after initialization if it's a regression problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdata_mem_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_approximate_df_mem_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mapprox_mem_size_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mem_usage\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_mem_usage\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_classes\u001b[0m  \u001b[0;31m# TODO: Extremely crude approximation, can be vastly improved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapprox_mem_size_req\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/pandas_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpackage_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_log_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mpackage_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_log_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/pandas_utils.py\u001b[0m in \u001b[0;36mget_approximate_df_mem_usage\u001b[0;34m(df, sample_ratio)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcolumns_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtypes_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mR_CATEGORY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcolumns_inexact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtypes_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mR_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_FLOAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_CATEGORY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mmemory_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns_category\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_category\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(self, index, deep)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \"\"\"\n\u001b[1;32m   3262\u001b[0m         result = self._constructor_sliced(\n\u001b[0;32m-> 3263\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3261\u001b[0m         \"\"\"\n\u001b[1;32m   3262\u001b[0m         result = self._constructor_sliced(\n\u001b[0;32m-> 3263\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_item_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3932\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3934\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3936\u001b[0m             \u001b[0;31m# for a chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    try:\n",
    "        if len(os.listdir(label)) > 1:\n",
    "             continue\n",
    "    except:\n",
    "        print('Working on' + label)\n",
    "    \n",
    "    labelData = labelsDataOriginal[[label]]    \n",
    "    trainDataSet = pd.concat([trainData, labelData], axis = 1)\n",
    "    \n",
    "    #first time training \n",
    "    save_path = label + '/' + 'GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Model_' + label \n",
    "    multi_predictor = MultilabelPredictor(labels=[label], problem_types=problem_types, eval_metrics=eval_metrics, path=save_path)\n",
    "    multi_predictor.fit(trainDataSet, time_limit=time_limit)\n",
    "    #multi_predictor = MultilabelPredictor.load(save_path)\n",
    "    #result = multi_predictor.predict(predictData)\n",
    "    #result.to_csv(label + '/' + 'GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Result_' + label+ '.csv')\n",
    "    \n",
    "    #get feature importance\n",
    "    predictor = multi_predictor.get_predictor(label)\n",
    "    feature_importance = predictor.feature_importance(trainDataSet[trainDataSet[label] > float('-inf')], num_shuffle_sets = 3)\n",
    "    feature_importance.to_csv(label + '/' + \"GlioML_feature_importance_\" + label + \".csv\")\n",
    "    \n",
    "    del labelData, trainDataSet, feature_importance, multi_predictor\n",
    "#     #only consider feature has positive contribution\n",
    "#     feature_importance = feature_importance[feature_importance['importance'] > 0]\n",
    "    \n",
    "#     #Evaluation\n",
    "#     evaaluateResult = []\n",
    "#     for top in tops:\n",
    "#         reducedfeatures = list(feature_importance[:top].index)\n",
    "#         trainDataR =  trainData[reducedfeatures]\n",
    "#         trainDataSetR = pd.concat([trainDataR,labelData],axis = 1)\n",
    "#         save_path_R = label + '/' + 'GlioML_ReducedFeature_' + str(top) + '_' + label + '_FeatureEvaluationModel'\n",
    "#         train, evaldata = train_test_split(trainDataSetR,test_size = 0.2,random_state=1112)\n",
    "#         predictor_single = MultilabelPredictor(labels=[label], problem_types=problem_types, eval_metrics=eval_metrics, path=save_path_R)\n",
    "#         predictor_single.fit(train, time_limit=time_limit)\n",
    "#         #predictor_single = MultilabelPredictor.load(save_path_R)\n",
    "#         evaluationData = predictor_single.evaluate(evaldata)\n",
    "#         evaaluateResult.append(evaluationData[label]['mean_squared_error'])\n",
    "#         if(top == 100):\n",
    "#             save_path_final = label + '/' + 'GiloML_predictDrugAUC_Top_100_Features_Best_Quality_Full_Data_Model_' + label\n",
    "#             predictor_single = MultilabelPredictor(labels = [label], problem_types = problem_types, eval_metrics = eval_metrics, path = save_path_final)\n",
    "#             predictor_single.fit(trainDataSetR, final = True, time_limit = time_limit)\n",
    "#             #result_final = predictor_single.predict(predictData[reducedfeatures])\n",
    "#             #result_final.to_csv(save_path_final + \"_Result.csv\")\n",
    "    \n",
    "#     maxPerformanceFeatureCount = tops[evaaluateResult.index(max(evaaluateResult))]\n",
    "#     evaaluateResult = [['Component Name','TOP100','TOP300','TOP600'], [label] + evaaluateResult]\n",
    "#     with open(label + '/' + 'GlioML_ReducedFeature_evalScore_' + label + '.csv', 'w', newline='') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         writer.writerows(evaaluateResult)\n",
    "    \n",
    "#     if maxPerformanceFeatureCount > 100: \n",
    "#         reducedfeatures = list(feature_importance[:maxPerformanceFeatureCount].index)\n",
    "#         trainDataR =  trainData[reducedfeatures]\n",
    "#         trainDataSetR = pd.concat([trainDataR,labelData],axis = 1)\n",
    "#         save_path_final = label + '/' + 'GiloML_predictDrugAUC_Top_' + str(maxPerformanceFeatureCount) +'_Features_Best_Quality_Full_Data_Model_' + label\n",
    "#         predictor_single = MultilabelPredictor(labels = [label], problem_types = problem_types, eval_metrics = eval_metrics, path = save_path_final)\n",
    "#         predictor_single.fit(trainDataSetR, final = True, time_limit = time_limit)\n",
    "#         #result_final = predictor_single.predict(predictData[reducedfeatures])\n",
    "#         #result_final.to_csv(save_path_final + \"_Result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffd795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e7bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eba2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
