{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55bed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.002621Z",
     "start_time": "2023-09-19T11:23:33.612609Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b72ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.018627Z",
     "start_time": "2023-09-19T11:23:35.003622Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=False, **kwargs):\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, final = False, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        start = time.time()\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...{i / len(self.labels) * 100}%\")\n",
    "            print(f\"{(time.time() - start) / 60} minutes\")\n",
    "            if (final):\n",
    "                predictor.fit(train_data=train_data[train_data[label] > float('-inf')]\n",
    "                              , tuning_data = tuning_data\n",
    "                              ,presets = 'best_quality'\n",
    "                              ,num_bag_folds = 5,num_bag_sets = 2\n",
    "                              , **kwargs)\n",
    "            else:\n",
    "                predictor.fit(train_data=train_data[train_data[label] > float('-inf')]\n",
    "                              , tuning_data = tuning_data\n",
    "                              ,presets = 'medium_quality'\n",
    "                              #,presets = 'best_quality'\n",
    "                              #,num_bag_folds = 5,num_bag_sets = 2\n",
    "                              , **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            \n",
    "            eval_dict[label] = predictor.evaluate(data[data[label] > float('-inf')], **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for i,label in enumerate(self.labels):\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...{i / len(self.labels) * 100}%\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae94b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.066622Z",
     "start_time": "2023-09-19T11:23:35.020623Z"
    }
   },
   "outputs": [],
   "source": [
    "#1 Load my ccl's ssGSEA signature\n",
    "myCCLSignature = []\n",
    "for name in ['sample.c2.cp.biocarta.gct',\n",
    "             'sample.c2.cp.kegg.gct',\n",
    "             'sample.c2.cp.pid.gct',\n",
    "             'sample.c2.cp.reactome.gct',\n",
    "             'sample.c2.cp.wiki.gct',\n",
    "             'sample.c6.gct',\n",
    "             'sample.hallmark.gct']:    \n",
    "    with open(name, mode ='r')as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        CCLSignature = list(csvFile)[2:]\n",
    "        print(len(CCLSignature))\n",
    "    for i, row in enumerate(CCLSignature):\n",
    "        temp = CCLSignature[i][0].split('\\t')\n",
    "        if i > 0:\n",
    "            CCLSignature[i] = [temp[0]] + [float(d) for d in temp[2:]]\n",
    "        else:\n",
    "            CCLSignature[i] = [temp[0]] + temp[2:]\n",
    "    if not myCCLSignature:\n",
    "        myCCLSignature += CCLSignature\n",
    "    else:\n",
    "        myCCLSignature += CCLSignature[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebef18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.824631Z",
     "start_time": "2023-09-19T11:23:35.068624Z"
    }
   },
   "outputs": [],
   "source": [
    "#2 Load CCLE ssGSEA signature\n",
    "CCLECCLSignature = []\n",
    "for name in ['ccle.c2.cp.biocarta.gct',\n",
    "             'ccle.c2.cp.kegg.gct',\n",
    "             'ccle.c2.cp.pid.gct',\n",
    "             'ccle.c2.cp.reactome.gct',\n",
    "             'ccle.c2.cp.wiki.gct',\n",
    "             'ccle.c6.gct',\n",
    "             'ccle.hallmark.gct']:\n",
    "    with open(name, mode ='r')as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        CCLSignature = list(csvFile)[2:]\n",
    "        print(len(CCLSignature))\n",
    "    for i, row in enumerate(CCLSignature):\n",
    "        temp = CCLSignature[i][0].split('\\t')\n",
    "        CCLSignature[i] = [temp[0]] + temp[2:]\n",
    "    if not CCLECCLSignature:\n",
    "        CCLECCLSignature += CCLSignature\n",
    "    else:\n",
    "        CCLECCLSignature += CCLSignature[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b85673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.840632Z",
     "start_time": "2023-09-19T11:23:35.825633Z"
    }
   },
   "outputs": [],
   "source": [
    "############new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6136f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.872630Z",
     "start_time": "2023-09-19T11:23:35.843636Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.1 load model\n",
    "modelMetaData = pd.read_csv('Model.csv', header=0)\n",
    "modelMetaData = modelMetaData[['ModelID','Age','Sex']]\n",
    "sex_mapping = {'Male': 1, 'Female': 0}\n",
    "modelMetaData['Sex'] = modelMetaData['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb2549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:35.920633Z",
     "start_time": "2023-09-19T11:23:35.874636Z"
    }
   },
   "outputs": [],
   "source": [
    "metaDataDict = {}\n",
    "for index, row in modelMetaData.iterrows():\n",
    "    key = row['ModelID'] \n",
    "    value = [row['Age'], row['Sex']] \n",
    "    if key not in metaDataDict:\n",
    "        metaDataDict[key] = value\n",
    "    else:\n",
    "        raise Exception(\"duplicated Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62ef3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:40.740325Z",
     "start_time": "2023-09-19T11:23:35.922631Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.2 load Mutation\n",
    "mutationData = pd.read_csv('OmicsSomaticMutations.csv')\n",
    "mutationData = mutationData[['ModelID','HugoSymbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e741d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:23:40.756304Z",
     "start_time": "2023-09-19T11:23:40.741283Z"
    }
   },
   "outputs": [],
   "source": [
    "candidateKeyList = [\n",
    "    'MGMT', 'IDH1', 'IDH2', 'EGFR',\n",
    "    'TTN', 'MAPRE3', 'TP53', 'PIK3C2B', 'CIC', 'LRP2', 'LRP1', 'NRXN2', 'TEAD2', 'MYH3', 'NOTCH1', 'TFE3', 'PIK3R1', 'FRMD4A', 'PRCC', 'CHD3', 'BAG6', 'GLYR1', 'ADAM23', 'MSH6', 'ATRX',\n",
    "    'MUC16', 'PTEN', 'NF1', 'OBSN', 'FLG', 'RYR2', 'MUC17',\n",
    "    'BRAF', 'CDKN2A', 'CDKN2B', 'TERT', 'MYC'\n",
    "]\n",
    "candidateGeneMutationCount = {key: 0 for key in candidateKeyList}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560b348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.003864Z",
     "start_time": "2023-09-19T11:23:40.759307Z"
    }
   },
   "outputs": [],
   "source": [
    "mutationDataDict = {}\n",
    "for index, row in mutationData.iterrows():\n",
    "    key = row['ModelID']\n",
    "    if key not in mutationDataDict:\n",
    "        mutationDataDict[key] = candidateGeneMutationCount.copy()\n",
    "    gene = row['HugoSymbol']\n",
    "    if gene in candidateGeneMutationCount:\n",
    "        mutationDataDict[key][row['HugoSymbol']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b0a4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.019876Z",
     "start_time": "2023-09-19T11:24:00.004821Z"
    }
   },
   "outputs": [],
   "source": [
    "#############new end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce386d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.115879Z",
     "start_time": "2023-09-19T11:24:00.021832Z"
    }
   },
   "outputs": [],
   "source": [
    "#3 Load CTRP cclName to AUC map\n",
    "cclToAUCdict = collections.defaultdict(list)\n",
    "with open('CTRP_CCL_AUC.gct', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    CTRPCCLAUC = list(csvFile)\n",
    "    CTRPCCLAUC = [''.join(sub).split('\\t') for sub in CTRPCCLAUC]\n",
    "    cclNames = CTRPCCLAUC[3][4:]\n",
    "\n",
    "for i,cclName in enumerate(cclNames):\n",
    "    cclToAUCdict[cclName] = [float( '-inf' if sub[4+i] == 'NaN' else sub[4+i]) for sub in CTRPCCLAUC[7:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc80f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.163833Z",
     "start_time": "2023-09-19T11:24:00.116833Z"
    }
   },
   "outputs": [],
   "source": [
    "#4 Load ccleID to ctrpName map\n",
    "CCLEidToCTRPNameDict = collections.defaultdict(str)\n",
    "CCLEidToDiseaseName = collections.defaultdict(str)\n",
    "with open('sample_info.csv', mode ='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    mapInfos = list(csvFile)\n",
    "    for mapInfo in mapInfos[1:]:\n",
    "        CCLEidToCTRPNameDict[mapInfo[0]] = mapInfo[2]  \n",
    "        CCLEidToDiseaseName[mapInfo[0]] = mapInfo[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996ddbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:00.179832Z",
     "start_time": "2023-09-19T11:24:00.164832Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53a03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.228441Z",
     "start_time": "2023-09-19T11:24:00.180832Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction data \n",
    "predictData = pd.DataFrame(data = myCCLSignature).transpose()\n",
    "new_header = predictData.iloc[0] \n",
    "predictData = predictData[1:] \n",
    "predictData.columns = new_header \n",
    "predictData = predictData.apply(pd.to_numeric, errors='ignore')\n",
    "predictData = predictData.set_index(['Name'])\n",
    "predictData = normalize(predictData)\n",
    "predictData = predictData.astype('float16')\n",
    "predictData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a614de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.420442Z",
     "start_time": "2023-09-19T11:24:01.230441Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictData.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6935a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:01.626443Z",
     "start_time": "2023-09-19T11:24:01.421443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare train set\n",
    "trainData = pd.DataFrame(data = CCLECCLSignature).transpose()\n",
    "new_header = trainData.iloc[0] \n",
    "trainData = trainData[1:] \n",
    "trainData.columns = new_header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52014506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.327450Z",
     "start_time": "2023-09-19T11:24:01.627444Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter valid ID\n",
    "validSet = set()\n",
    "for name in trainData['Name']:\n",
    "    if CCLEidToCTRPNameDict[name] in cclToAUCdict:\n",
    "        validSet.add(name)\n",
    "trainData = trainData.loc[trainData['Name'].isin(validSet)]\n",
    "trainData = trainData.reset_index(drop = True)\n",
    "trainData = trainData.set_index(['Name'])\n",
    "trainData = trainData.apply(pd.to_numeric)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce4112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.390964Z",
     "start_time": "2023-09-19T11:24:02.375965Z"
    }
   },
   "outputs": [],
   "source": [
    "if not all(trainData.columns == predictData.columns):\n",
    "    raise Exception(\"Column do not match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c8b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.406965Z",
     "start_time": "2023-09-19T11:24:02.391964Z"
    }
   },
   "outputs": [],
   "source": [
    "###new\n",
    "trainData['Age'] = trainData.index.map(lambda x: metaDataDict[x][0])\n",
    "trainData['Sex'] = trainData.index.map(lambda x: metaDataDict[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed8251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:02.437967Z",
     "start_time": "2023-09-19T11:24:02.408964Z"
    }
   },
   "outputs": [],
   "source": [
    "#counts not matter\n",
    "for geneName in candidateKeyList:\n",
    "    trainData[geneName] = trainData.index.map(lambda x: 1 if x in mutationDataDict and mutationDataDict[x][geneName] > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770b06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:04.902903Z",
     "start_time": "2023-09-19T11:24:02.440964Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData = normalize(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fb296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.124906Z",
     "start_time": "2023-09-19T11:24:04.904905Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData = trainData.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d3930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.139907Z",
     "start_time": "2023-09-19T11:24:05.125906Z"
    }
   },
   "outputs": [],
   "source": [
    "### new end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9ca95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.586929Z",
     "start_time": "2023-09-19T11:24:05.140908Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#labels data\n",
    "labelsDataOriginal = pd.DataFrame(columns = [sub[1] for sub in CTRPCCLAUC[7:]])\n",
    "for name in trainData.index:\n",
    "    labelsDataOriginal.loc[len(labelsDataOriginal.index)] = cclToAUCdict[CCLEidToCTRPNameDict[name]]\n",
    "labelsDataOriginal = labelsDataOriginal.set_index(trainData.index)\n",
    "labelsDataOriginal = labelsDataOriginal.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b49a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.634930Z",
     "start_time": "2023-09-19T11:24:05.604930Z"
    }
   },
   "outputs": [],
   "source": [
    "#add high priority at the begining. e.g dasatinib\n",
    "labels = list(labelsDataOriginal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062064dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:24:05.650931Z",
     "start_time": "2023-09-19T11:24:05.635931Z"
    }
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "problem_types = ['regression'] \n",
    "eval_metrics = ['mean_squared_error']\n",
    "time_limit = 60 * 60 * 24\n",
    "tops = [100,300,600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fece86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDataOriginal.info(memory_usage = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029b871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T11:40:04.997510Z",
     "start_time": "2023-09-19T11:28:16.854634Z"
    }
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    try:\n",
    "        if len(os.listdir(label)) > 1:\n",
    "             continue\n",
    "    except:\n",
    "        print('Working on' + label)\n",
    "    \n",
    "    labelData = labelsDataOriginal[[label]]    \n",
    "    trainDataSet = pd.concat([trainData, labelData], axis = 1)\n",
    "    \n",
    "    #first time training \n",
    "    save_path = label + '/' + 'GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Model_' + label \n",
    "    multi_predictor = MultilabelPredictor(labels=[label], problem_types=problem_types, eval_metrics=eval_metrics, path=save_path)\n",
    "    multi_predictor.fit(trainDataSet, time_limit=time_limit)\n",
    "    #multi_predictor = MultilabelPredictor.load(save_path)\n",
    "    #result = multi_predictor.predict(predictData)\n",
    "    #result.to_csv(label + '/' + 'GiloML_predictDrugAUC_Full_Feature_Medium_Quality_Result_' + label+ '.csv')\n",
    "    \n",
    "    #get feature importance\n",
    "    predictor = multi_predictor.get_predictor(label)\n",
    "    feature_importance = predictor.feature_importance(trainDataSet[trainDataSet[label] > float('-inf')], num_shuffle_sets = 3)\n",
    "    feature_importance.to_csv(label + '/' + \"GlioML_feature_importance_\" + label + \".csv\")\n",
    "    \n",
    "    #only consider feature has positive contribution\n",
    "    feature_importance = feature_importance[feature_importance['importance'] > 0]\n",
    "    \n",
    "#     #Evaluation\n",
    "#     evaaluateResult = []\n",
    "#     for top in tops:\n",
    "#         reducedfeatures = list(feature_importance[:top].index)\n",
    "#         trainDataR =  trainData[reducedfeatures]\n",
    "#         trainDataSetR = pd.concat([trainDataR,labelData],axis = 1)\n",
    "#         save_path_R = label + '/' + 'GlioML_ReducedFeature_' + str(top) + '_' + label + '_FeatureEvaluationModel'\n",
    "#         train, evaldata = train_test_split(trainDataSetR,test_size = 0.2,random_state=1112)\n",
    "#         predictor_single = MultilabelPredictor(labels=[label], problem_types=problem_types, eval_metrics=eval_metrics, path=save_path_R)\n",
    "#         predictor_single.fit(train, time_limit=time_limit)\n",
    "#         #predictor_single = MultilabelPredictor.load(save_path_R)\n",
    "#         evaluationData = predictor_single.evaluate(evaldata)\n",
    "#         evaaluateResult.append(evaluationData[label]['mean_squared_error'])\n",
    "#         if(top == 100):\n",
    "#             save_path_final = label + '/' + 'GiloML_predictDrugAUC_Top_100_Features_Best_Quality_Full_Data_Model_' + label\n",
    "#             predictor_single = MultilabelPredictor(labels = [label], problem_types = problem_types, eval_metrics = eval_metrics, path = save_path_final)\n",
    "#             predictor_single.fit(trainDataSetR, final = True, time_limit = time_limit)\n",
    "#             #result_final = predictor_single.predict(predictData[reducedfeatures])\n",
    "#             #result_final.to_csv(save_path_final + \"_Result.csv\")\n",
    "    \n",
    "#     maxPerformanceFeatureCount = tops[evaaluateResult.index(max(evaaluateResult))]\n",
    "#     evaaluateResult = [['Component Name','TOP100','TOP300','TOP600'], [label] + evaaluateResult]\n",
    "#     with open(label + '/' + 'GlioML_ReducedFeature_evalScore_' + label + '.csv', 'w', newline='') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         writer.writerows(evaaluateResult)\n",
    "    \n",
    "#     if maxPerformanceFeatureCount > 100: \n",
    "#         reducedfeatures = list(feature_importance[:maxPerformanceFeatureCount].index)\n",
    "#         trainDataR =  trainData[reducedfeatures]\n",
    "#         trainDataSetR = pd.concat([trainDataR,labelData],axis = 1)\n",
    "#         save_path_final = label + '/' + 'GiloML_predictDrugAUC_Top_' + str(maxPerformanceFeatureCount) +'_Features_Best_Quality_Full_Data_Model_' + label\n",
    "#         predictor_single = MultilabelPredictor(labels = [label], problem_types = problem_types, eval_metrics = eval_metrics, path = save_path_final)\n",
    "#         predictor_single.fit(trainDataSetR, final = True, time_limit = time_limit)\n",
    "#         #result_final = predictor_single.predict(predictData[reducedfeatures])\n",
    "#         #result_final.to_csv(save_path_final + \"_Result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffd795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e7bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eba2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
